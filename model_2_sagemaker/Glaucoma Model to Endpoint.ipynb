{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploying Glaucoma Keras Model Using Amazon SageMaker\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='eye-model.png' width=\"1000\" height=\"300\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**By: Pieter Leffers**\n",
    "\n",
    "*Completion Date: June 3, 2019*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the Keras model has been been trained and saved its time to deploy the model for use. Although you may use flask and a web framework from scratch to deploy the model; however, doing so would be beyond the scope of this project for sure. For ease and simplicity AWS Sagemaker is a good choice, but I have found during the course of this project that although Sagemaker makes it easy to host and deploy your models, the documentation on doing so isn't necessarily good and doesn't have the ease of functionality that I would prefer. Fortunately for others whom have trained their own models in Keras, you can follow this notebook to deploy a model and create a Sagemaker endpoint in order to connect to a web framework and start running inferencing on batches of data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: If you haven't gone through my previous project notebook on creating and training the glaucoma model; you will need to know that your trained model will need to be saved in the Keras JSON and weights hdf5 format. The Keras JSON file will contain your model architecture and the hdf5 will contain your model weights.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Start Sagemaker Instance**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='sage1.png' width=\"1000\" height=\"300\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Click on **'Create notebook instance'** and provide the details needed to start the instance. For my needs I started an **ml.m4.xlarge** instance since which has 4 virtual cpus and 16 gigs of ram, which is fairly equivalent to my local computer architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='sage2.png' width=\"1000\" height=\"300\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "In the AWS Management Console, go to the Amazon SageMaker console and choose a *'Notebook Instance'*, as opposed to a *'Jupyter Lab'* instance and create a new notebook instance. Using the 'Upload' button, upload my notebook from my github set the kernel to **conda_tensorflow_p36**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='sage3.png' width=\"300\" height=\"300\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='sage4.png' width=\"500\" height=\"300\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling the get_execution_role function retrieves the AWS Identity and Access Management (IAM) role created at the time of creating the notebook instance. Here I am storing the execution_role in the variable name *role*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3, re\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a directory called keras_model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir keras_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then navigate to the 'Home' tab and choose 'Open JupyterLab'. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='sage3.png' width=\"300\" height=\"300\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once JupyterLab is open click on the up arrow on the left-hand menu and upload the **glaucoma_model_architecture.json**, **glaucoma_model_weights.h5**, **5.png**, and **11.png** files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='sage5.png' width=\"500\" height=\"300\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: the reason you switch to JupyterLab is because the model **glaucoma_model_weights.h5** file returns a file size warning which the original notebook will fail to provide. Be aware that because of the size and the error, the **glaucoma_model_weights.h5** file may need to be uploaded multiple times. I have also found that it takes a few minutes to load so I would recommend to be patient here. Also I am primarily choosing to work in Jupyter Notebook as opposed to JupyterLab because I have found the Notebook to be more stable.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='sage6.png' width=\"500\" height=\"300\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can return to the original notebook instance and run the code in the cell below to see that those files are present. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls keras_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now upload we can upload the model files into Sagemaker**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: ignore the warning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "json_file = open('/home/ec2-user/SageMaker/keras_model/'+'glaucoma_model_architecture.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: this portion will also take a few minutes to load*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "loaded_model.load_weights('/home/ec2-user/SageMaker/keras_model/glaucoma_model_weights.h5')\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the Keras model to the TensorFlow ProtoBuf format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.saved_model import builder\n",
    "from tensorflow.python.saved_model.signature_def_utils import predict_signature_def\n",
    "from tensorflow.python.saved_model import tag_constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The directory structure outlined below will need to be followed exactly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_version = '1'\n",
    "export_dir = 'export/Servo/' + model_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the Protocol Buffer SavedModel at 'export_dir'\n",
    "builder = builder.SavedModelBuilder(export_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: ignore the warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:205: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n"
     ]
    }
   ],
   "source": [
    "# Create prediction signature to be used by TensorFlow Serving Predict API\n",
    "signature = predict_signature_def(\n",
    "    inputs={\"inputs\": loaded_model.input}, outputs={\"score\": loaded_model.output})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Start a Keras Session**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: export/Servo/1/saved_model.pb\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "with K.get_session() as sess:\n",
    "    # Save the meta graph and variables\n",
    "    builder.add_meta_graph_and_variables(\n",
    "        sess=sess, tags=[tag_constants.SERVING], signature_def_map={\"serving_default\": signature})\n",
    "    builder.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert TensorFlow model to a SageMaker readable format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Move the TensorFlow exported model into the directory export\\Servo\\. SageMaker will recognize this as a loadable TensorFlow model. Your directory and file structure should look like: \n",
    "\n",
    "    export/Servo/1/\n",
    "    variables.data-00000-of-00001  variables.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Servo\r\n"
     ]
    }
   ],
   "source": [
    "!ls export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\r\n"
     ]
    }
   ],
   "source": [
    "!ls export/Servo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved_model.pb\tvariables\r\n"
     ]
    }
   ],
   "source": [
    "!ls export/Servo/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variables.data-00000-of-00001  variables.index\r\n"
     ]
    }
   ],
   "source": [
    "!ls export/Servo/1/variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Tar the entire directory and upload to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "with tarfile.open('model.tar.gz', mode='w:gz') as archive:\n",
    "    archive.add('export', recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "inputs = sagemaker_session.upload_data(path='model.tar.gz', key_prefix='model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the trained model\n",
    "\n",
    "*Note: The entry_point file \"train.py\" can be an empty Python file.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "!touch train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now start *TensorFlowModel* function, using the parameters below.\n",
    "\n",
    "*Note: I followed the warning below using \"py_version='py3'\" and the instance wouldn't start. So I would recommend leaving the option at python 2.7 for now.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The Python 2 tensorflow images will be soon deprecated and may not be supported for newer upcoming versions of the tensorflow images.\n",
      "Please set the argument \"py_version='py3'\" to use the Python 3 tensorflow image.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.tensorflow.model import TensorFlowModel\n",
    "sagemaker_model = TensorFlowModel(model_data = 's3://' + sagemaker_session.default_bucket() + '/model/model.tar.gz',\n",
    "                                  role = role,\n",
    "                                  framework_version = '1.12',\n",
    "                                  entry_point = 'train.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now deploy the algorithm to the instance. This will take quite awhile so you will need to relax until it completes without interrupting anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------!CPU times: user 582 ms, sys: 37.3 ms, total: 619 ms\n",
      "Wall time: 8min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictor = sagemaker_model.deploy(initial_instance_count=1,\n",
    "                                   instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to update the endpoint in the cell below with the endpoint name from the output of the previous cell. You can simply navigate to the Sagemaker console, click on 'Endpoints' and copy the 'Name' in the box. Then paste it in the cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='sage7.png' width=\"500\" height=\"300\" align=\"left\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = 'sagemaker-tensorflow-2019-06-03-21-51-31-059'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can set the TensorFlowPredictor to the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.tensorflow.model import TensorFlowModel\n",
    "predictor=sagemaker.tensorflow.model.TensorFlowPredictor(endpoint_name, sagemaker_session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Invoking the endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I that I have all the pieces in place I want to make sure that the predicor function can properly make predictions from the algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "import pandas as pd\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load image function to prepare an image into tensor format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(img_path, show=False):\n",
    "    # (height, width, channels)\n",
    "    img = image.load_img(img_path, target_size=(64, 64))\n",
    "    # (1, height, width, channels), add a dimension because the model expects this shape:\n",
    "    # (batch_size, height, width, channels)\n",
    "    img_tensor = image.img_to_array(img)                    \n",
    "    img_tensor = np.expand_dims(img_tensor, axis=0) \n",
    "    # imshow expects values in the range [0, 1]\n",
    "    img_tensor /= 255.                                      \n",
    "\n",
    "    if show:\n",
    "        plt.imshow(img_tensor[0])                           \n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    return img_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the path to the image files we uploaded before. These images come from the validation set, which isn't stricly kosher, but this is more for demonstration purposes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image path\n",
    "img_path_case = '/home/ec2-user/SageMaker/keras_model/11.png'    \n",
    "img_path_control = '/home/ec2-user/SageMaker/keras_model/5.png'    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Invoke the load_image function and invoke the SageMaker endpoint from the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a single image\n",
    "new_image = load_image(img_path_case)\n",
    "\n",
    "# check prediction\n",
    "pred = predictor.predict(new_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the results below (float_val) we can see we are 0.99976 sure that the image is a case of Glaucoma vs. 0.00233 sure that we are dealing with a normal retina image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'outputs': {'score': {'dtype': 1,\n",
       "   'tensor_shape': {'dim': [{'size': 1}, {'size': 2}]},\n",
       "   'float_val': [0.9976667165756226, 0.0023333081044256687]}},\n",
       " 'model_spec': {'name': 'generic_model',\n",
       "  'version': {'value': 1},\n",
       "  'signature_name': 'serving_default'}}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what the image looks like..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64 at 0x7FE3F92A0438>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = load_img(img_path_case, target_size=(64, 64))\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*...If you are following along with this notebook, try changing the example image to **'img_path_control'** and see how the prediction changes.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Invoke the SageMaker endpoint using a boto3 client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see the endpoint is live and can serve predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'{\\n  \"outputs\": {\\n    \"score\": {\\n      \"dtype\": \"DT_FLOAT\", \\n      \"floatVal\": [\\n        0.9976667165756226, \\n        0.0023333081044256687\\n      ], \\n      \"tensorShape\": {\\n        \"dim\": [\\n          {\\n            \"size\": \"1\"\\n          }, \\n          {\\n            \"size\": \"2\"\\n          }\\n        ]\\n      }\\n    }\\n  }, \\n  \"modelSpec\": {\\n    \"version\": \"1\", \\n    \"name\": \"generic_model\", \\n    \"signatureName\": \"serving_default\"\\n  }\\n}'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import boto3\n",
    "import numpy as np\n",
    "import io\n",
    " \n",
    "client = boto3.client('runtime.sagemaker')\n",
    "# The sample model expects an input of shape [1,50]\n",
    "data = new_image.tolist()\n",
    "response = client.invoke_endpoint(EndpointName=endpoint_name, Body=json.dumps(data))\n",
    "response_body = response['Body']\n",
    "print(response_body.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the algorithm has been fully deployed to an AWS endpoint and can serve predictions I have finally chosen to close down the endpoint and delete all of the resources in order to avoid any unecessary charges since this has been primarily for demonstration purposes. However, if this was in a full production environment you could in theory, easily connect the AWS endpoint to your web application or web framework to host the algorithm and pass data through it in order to get predictions. That being said, this is about as far as I can take this project without creating a whole web-application / front-end for a data pipeline; which would involve a number of skills normally outside of the Data Science spectrum. \n",
    "\n",
    "*So what have I demonstrated throughout this project?*\n",
    "\n",
    "We have seen the entire life-cycle of an algorithm from doing background research, to development and training of a model, to final deployment of a model to a space where it can serve predictions on a dataset. Just like in most  scientific work I would say that at each point of the project there are places to improve; from background research all the way to deployment. However, I feel for the purposes of this project things are at a fairly complete stage without spending unfortunate amounts of hours without spinning my wheels refining details. We have seen the algorithm has at least a 90% accuracy, which means that 9 out of 10 times when the algorithm makes a prediction, it is an accurate prediction. I think it should be abundantly clear that I never intend for these predictions to replace an opthimologist's diagnosis, but it may perhaps to be useful for diagnostic purposes which is the best I could hope for.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
